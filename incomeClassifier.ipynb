{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data into a pandas DataFrame with custom delimiter\n",
    "df_train = pd.read_csv('adult.data', header=None, delimiter=\", \", engine='python')\n",
    "df_test = pd.read_csv('adult.test', header=None, delimiter=\", \", engine='python')\n",
    "\n",
    "# Replace '?' with NaN for easier handling\n",
    "df_train.replace('?', np.nan, inplace=True)\n",
    "df_test.replace('?', np.nan, inplace=True)\n",
    "\n",
    "# Drop rows with any missing values and reset index\n",
    "df_train = df_train.dropna().reset_index(drop=True)\n",
    "df_test = df_test.dropna().reset_index(drop=True)\n",
    "\n",
    "# Extract the data (excluding the target column)\n",
    "training_data = df_train.iloc[:, :-1]\n",
    "testing_data = df_test.iloc[:, :-1]\n",
    "\n",
    "# Extract the target variable and transform it\n",
    "training_target = df_train.iloc[:, -1]\n",
    "training_target = (training_target == '>50K').astype(int)\n",
    "testing_target = df_test.iloc[:, -1]\n",
    "testing_target = (testing_target == '>50K.').astype(int)\n",
    "\n",
    "# Select categorical columns for one-hot encoding\n",
    "categorical_columns = [1, 3, 5, 6, 7, 8, 9, 13]\n",
    "numerical_columns = [0, 2, 4, 10, 11, 12]\n",
    "\n",
    "# Apply one-hot encoding to categorical columns\n",
    "encoder = OneHotEncoder(sparse_output=False, drop='first')  # drop='first' to avoid multicollinearity\n",
    "encoded_training_data = encoder.fit_transform(training_data.iloc[:, categorical_columns])\n",
    "encoded_testing_data = encoder.fit_transform(testing_data.iloc[:, categorical_columns])\n",
    "\n",
    "# Concatenate encoded data with numerical columns\n",
    "training_data = np.concatenate([encoded_training_data, training_data.iloc[:, numerical_columns]], axis=1)\n",
    "testing_data = np.concatenate([encoded_testing_data, testing_data.iloc[:, numerical_columns]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA:\n",
      "- Testing accuracy: 0.8389\n",
      "- Precision: 0.7164\n",
      "- Recall: 0.5700\n",
      "- F1-score: 0.6349\n",
      "- AUC-ROC: 0.7482\n"
     ]
    }
   ],
   "source": [
    "X_train = training_data  # Features\n",
    "y_train = training_target  # Target variable\n",
    "X_test = testing_data\n",
    "y_test = testing_target\n",
    "\n",
    "# Train LDA model\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(X_train, y_train)\n",
    "predictions_lda = lda.predict(X_test)\n",
    "\n",
    "# Calculate accuracy metrics for LDA\n",
    "accuracy_lda = accuracy_score(y_test, predictions_lda)\n",
    "precision_lda, recall_lda, f1_lda, _ = precision_recall_fscore_support(y_test, predictions_lda, average='binary')\n",
    "auc_roc_lda = roc_auc_score(y_test, predictions_lda)\n",
    "\n",
    "print(\"LDA:\")\n",
    "print(f\"- Testing accuracy: {accuracy_lda:.4f}\")\n",
    "print(f\"- Precision: {precision_lda:.4f}\")\n",
    "print(f\"- Recall: {recall_lda:.4f}\")\n",
    "print(f\"- F1-score: {f1_lda:.4f}\")\n",
    "print(f\"- AUC-ROC: {auc_roc_lda:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\sklearn\\discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QDA:\n",
      "- Testing accuracy: 0.7529\n",
      "- Precision: 0.3854\n",
      "- Recall: 0.0100\n",
      "- F1-score: 0.0195\n",
      "- AUC-ROC: 0.5024\n"
     ]
    }
   ],
   "source": [
    "# Train QDA model\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "qda.fit(X_train, y_train)\n",
    "predictions_qda = qda.predict(X_test)\n",
    "\n",
    "# Calculate accuracy metrics for LDA\n",
    "accuracy_qda = accuracy_score(y_test, predictions_qda)\n",
    "precision_qda, recall_qda, f1_qda, _ = precision_recall_fscore_support(y_test, predictions_qda, average='binary')\n",
    "auc_roc_qda = roc_auc_score(y_test, predictions_qda)\n",
    "\n",
    "print(\"QDA:\")\n",
    "print(f\"- Testing accuracy: {accuracy_qda:.4f}\")\n",
    "print(f\"- Precision: {precision_qda:.4f}\")\n",
    "print(f\"- Recall: {recall_qda:.4f}\")\n",
    "print(f\"- F1-score: {f1_qda:.4f}\")\n",
    "print(f\"- AUC-ROC: {auc_roc_qda:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "- Testing Accuracy: 0.8476\n",
      "- Precision: 0.7292\n",
      "- Recall: 0.6041\n",
      "- F1-score: 0.6608\n",
      "- AUC-ROC: 0.7655\n"
     ]
    }
   ],
   "source": [
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train Logistic Regression model\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "predictions_log_reg = log_reg.predict(X_test_scaled)\n",
    "\n",
    "# Calculate accuracy metrics for Logistic Regression\n",
    "accuracy_log_reg = accuracy_score(y_test, predictions_log_reg)\n",
    "precision_log_reg, recall_log_reg, f1_log_reg, _ = precision_recall_fscore_support(y_test, predictions_log_reg, average='binary')\n",
    "auc_roc_log_reg = roc_auc_score(y_test, predictions_log_reg)\n",
    "\n",
    "print(\"Logistic Regression:\")\n",
    "print(f\"- Testing Accuracy: {accuracy_log_reg:.4f}\")\n",
    "print(f\"- Precision: {precision_log_reg:.4f}\")\n",
    "print(f\"- Recall: {recall_log_reg:.4f}\")\n",
    "print(f\"- F1-score: {f1_log_reg:.4f}\")\n",
    "print(f\"- AUC-ROC: {auc_roc_log_reg:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM:\n",
      "- Testing Accuracy: 0.8457\n",
      "- Precision: 0.7409\n",
      "- Recall: 0.5719\n",
      "- F1-score: 0.6455\n",
      "- AUC-ROC: 0.7534\n"
     ]
    }
   ],
   "source": [
    "# Train SVM model\n",
    "svm = SVC(kernel='rbf')  # You can specify different kernels (e.g., 'linear', 'poly', 'rbf')\n",
    "svm.fit(X_train_scaled, y_train)\n",
    "predictions_svm = svm.predict(X_test_scaled)\n",
    "\n",
    "# Calculate accuracy metrics for SVM\n",
    "accuracy_svm = accuracy_score(y_test, predictions_svm)\n",
    "precision_svm, recall_svm, f1_svm, _ = precision_recall_fscore_support(y_test, predictions_svm, average='binary')\n",
    "auc_roc_svm = roc_auc_score(y_test, predictions_svm)\n",
    "\n",
    "print(\"SVM:\")\n",
    "print(f\"- Testing Accuracy: {accuracy_svm:.4f}\")\n",
    "print(f\"- Precision: {precision_svm:.4f}\")\n",
    "print(f\"- Recall: {recall_svm:.4f}\")\n",
    "print(f\"- F1-score: {f1_svm:.4f}\")\n",
    "print(f\"- AUC-ROC: {auc_roc_svm:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "- Testing Accuracy: 0.8485\n",
      "- Precision: 0.7239\n",
      "- Recall: 0.6200\n",
      "- F1-score: 0.6679\n",
      "- AUC-ROC: 0.7715\n"
     ]
    }
   ],
   "source": [
    "# Train Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)  # You can adjust n_estimators and other hyperparameters\n",
    "rf_classifier.fit(X_train_scaled, y_train)\n",
    "predictions_rf = rf_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Calculate accuracy metrics for Random Forest\n",
    "accuracy_rf = accuracy_score(y_test, predictions_rf)\n",
    "precision_rf, recall_rf, f1_rf, _ = precision_recall_fscore_support(y_test, predictions_rf, average='binary')\n",
    "auc_roc_rf = roc_auc_score(y_test, predictions_rf)\n",
    "\n",
    "print(\"Random Forest:\")\n",
    "print(f\"- Testing Accuracy: {accuracy_rf:.4f}\")\n",
    "print(f\"- Precision: {precision_rf:.4f}\")\n",
    "print(f\"- Recall: {recall_rf:.4f}\")\n",
    "print(f\"- F1-score: {f1_rf:.4f}\")\n",
    "print(f\"- AUC-ROC: {auc_roc_rf:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting:\n",
      "- Testing Accuracy: 0.8663\n",
      "- Precision: 0.7929\n",
      "- Recall: 0.6168\n",
      "- F1-score: 0.6938\n",
      "- AUC-ROC: 0.7821\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Train the Gradient Boosting Classifier\n",
    "gb_classifier = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)  # Adjust hyperparameters as needed\n",
    "gb_classifier.fit(X_train_scaled, y_train)\n",
    "predictions_gb = gb_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Calculate accuracy metrics\n",
    "accuracy_gb = accuracy_score(y_test, predictions_gb)\n",
    "precision_gb, recall_gb, f1_gb, _ = precision_recall_fscore_support(y_test, predictions_gb, average='binary')\n",
    "auc_roc_gb = roc_auc_score(y_test, predictions_gb)\n",
    "\n",
    "print(\"Gradient Boosting:\")\n",
    "print(f\"- Testing Accuracy: {accuracy_gb:.4f}\")\n",
    "print(f\"- Precision: {precision_gb:.4f}\")\n",
    "print(f\"- Recall: {recall_gb:.4f}\")\n",
    "print(f\"- F1-score: {f1_gb:.4f}\")\n",
    "print(f\"- AUC-ROC: {auc_roc_gb:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA:\n",
      "- Testing accuracy: 0.8389\n",
      "- Precision: 0.7164\n",
      "- Recall: 0.5700\n",
      "- F1-score: 0.6349\n",
      "- AUC-ROC: 0.7482\n",
      "\n",
      "QDA:\n",
      "- Testing accuracy: 0.7529\n",
      "- Precision: 0.3854\n",
      "- Recall: 0.0100\n",
      "- F1-score: 0.0195\n",
      "- AUC-ROC: 0.5024\n",
      "\n",
      "Logistic Regression:\n",
      "- Testing Accuracy: 0.8476\n",
      "- Precision: 0.7292\n",
      "- Recall: 0.6041\n",
      "- F1-score: 0.6608\n",
      "- AUC-ROC: 0.7655\n",
      "\n",
      "SVM:\n",
      "- Testing Accuracy: 0.8457\n",
      "- Precision: 0.7409\n",
      "- Recall: 0.5719\n",
      "- F1-score: 0.6455\n",
      "- AUC-ROC: 0.7534\n",
      "\n",
      "Random Forest:\n",
      "- Testing Accuracy: 0.8485\n",
      "- Precision: 0.7239\n",
      "- Recall: 0.6200\n",
      "- F1-score: 0.6679\n",
      "- AUC-ROC: 0.7715\n",
      "\n",
      "Gradient Boosting:\n",
      "- Testing Accuracy: 0.8663\n",
      "- Precision: 0.7929\n",
      "- Recall: 0.6168\n",
      "- F1-score: 0.6938\n",
      "- AUC-ROC: 0.7821\n"
     ]
    }
   ],
   "source": [
    "# Print all accuracy metrics\n",
    "print(\"LDA:\")\n",
    "print(f\"- Testing accuracy: {accuracy_lda:.4f}\")\n",
    "print(f\"- Precision: {precision_lda:.4f}\")\n",
    "print(f\"- Recall: {recall_lda:.4f}\")\n",
    "print(f\"- F1-score: {f1_lda:.4f}\")\n",
    "print(f\"- AUC-ROC: {auc_roc_lda:.4f}\")\n",
    "print()\n",
    "\n",
    "print(\"QDA:\")\n",
    "print(f\"- Testing accuracy: {accuracy_qda:.4f}\")\n",
    "print(f\"- Precision: {precision_qda:.4f}\")\n",
    "print(f\"- Recall: {recall_qda:.4f}\")\n",
    "print(f\"- F1-score: {f1_qda:.4f}\")\n",
    "print(f\"- AUC-ROC: {auc_roc_qda:.4f}\")\n",
    "print()\n",
    "\n",
    "print(\"Logistic Regression:\")\n",
    "print(f\"- Testing Accuracy: {accuracy_log_reg:.4f}\")\n",
    "print(f\"- Precision: {precision_log_reg:.4f}\")\n",
    "print(f\"- Recall: {recall_log_reg:.4f}\")\n",
    "print(f\"- F1-score: {f1_log_reg:.4f}\")\n",
    "print(f\"- AUC-ROC: {auc_roc_log_reg:.4f}\")\n",
    "print()\n",
    "\n",
    "print(\"SVM:\")\n",
    "print(f\"- Testing Accuracy: {accuracy_svm:.4f}\")\n",
    "print(f\"- Precision: {precision_svm:.4f}\")\n",
    "print(f\"- Recall: {recall_svm:.4f}\")\n",
    "print(f\"- F1-score: {f1_svm:.4f}\")\n",
    "print(f\"- AUC-ROC: {auc_roc_svm:.4f}\")\n",
    "print()\n",
    "\n",
    "print(\"Random Forest:\")\n",
    "print(f\"- Testing Accuracy: {accuracy_rf:.4f}\")\n",
    "print(f\"- Precision: {precision_rf:.4f}\")\n",
    "print(f\"- Recall: {recall_rf:.4f}\")\n",
    "print(f\"- F1-score: {f1_rf:.4f}\")\n",
    "print(f\"- AUC-ROC: {auc_roc_rf:.4f}\")\n",
    "print()\n",
    "\n",
    "print(\"Gradient Boosting:\")\n",
    "print(f\"- Testing Accuracy: {accuracy_gb:.4f}\")\n",
    "print(f\"- Precision: {precision_gb:.4f}\")\n",
    "print(f\"- Recall: {recall_gb:.4f}\")\n",
    "print(f\"- F1-score: {f1_gb:.4f}\")\n",
    "print(f\"- AUC-ROC: {auc_roc_gb:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
